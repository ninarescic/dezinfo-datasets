{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaaea409",
   "metadata": {},
   "source": [
    "# Bluesky dataset overview (mounted)\n",
    "\n",
    "This notebook is a **lightweight, streaming-friendly overview** for the Bluesky dataset from Zenodo record **14669616**.\n",
    "\n",
    "**Key goal:** follow the same workflow as your Higgs notebook — you **mount the dataset on the server** and point the notebook at the mounted folder (no downloads).\n",
    "\n",
    "What you'll do here:\n",
    "\n",
    "1. Locate your repo root and load `SETTINGS.DATA_ROOT` from `src.core.config`\n",
    "2. Point to the mounted dataset directory\n",
    "3. Inspect what files are present (top-level)\n",
    "4. Peek at the main CSV/CSV.GZ files without loading them fully\n",
    "5. Compute basic graph stats for `followers.csv.gz` **streaming in chunks**\n",
    "6. Peek inside large `.tar.gz` archives **without extracting them**\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "096a16be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T11:53:07.846574Z",
     "start_time": "2026-01-30T11:53:07.758754Z"
    }
   },
   "source": [
    "# ============================================================\n",
    "# 0) Project setup (same pattern as Higgs notebook)\n",
    "#    - find repo root by locating `src/`\n",
    "#    - import SETTINGS from src.core.config\n",
    "# ============================================================\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "def find_repo_root(start: Path | None = None) -> Path:\n",
    "    start = (start or Path.cwd()).resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"src\").is_dir():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"Could not find repo root containing `src/`\")\n",
    "\n",
    "REPO_ROOT = find_repo_root()\n",
    "if str(REPO_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(REPO_ROOT))\n",
    "\n",
    "from src.core.config import SETTINGS  # noqa: E402\n",
    "\n",
    "print(\"REPO_ROOT:\", REPO_ROOT)\n",
    "print(\"DATA_ROOT:\", SETTINGS.DATA_ROOT)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO_ROOT: /mnt/c/Users/rescic/PycharmProjects/dezinfo-datasets\n",
      "DATA_ROOT: /home/rescic/dezinfo_data\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "afea8539",
   "metadata": {},
   "source": [
    "## 1) Point to the mounted dataset folder\n",
    "\n",
    "Mount the Zenodo dataset somewhere under `SETTINGS.DATA_ROOT`.\n",
    "\n",
    "Set `DATASET_SUBDIR` to the folder name you mounted (for example `bluesky_14669616/` or similar).\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "0c106a58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T11:53:26.135808Z",
     "start_time": "2026-01-30T11:53:26.117774Z"
    }
   },
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Change this to match your mount folder name under DATA_ROOT:\n",
    "DATASET_SUBDIR = \"bluesky\"  # <-- EDIT ME\n",
    "\n",
    "DATASET_DIR = Path(SETTINGS.DATA_ROOT) / DATASET_SUBDIR\n",
    "assert DATASET_DIR.exists(), f\"Mounted dataset folder not found: {DATASET_DIR}\"\n",
    "print(\"DATASET_DIR:\", DATASET_DIR)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET_DIR: /home/rescic/dezinfo_data/bluesky\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "fff03ba0",
   "metadata": {},
   "source": [
    "## 2) Discover what's in the dataset directory\n",
    "\n",
    "We look for commonly expected files (based on the Zenodo record), but we **don't assume** they're all present —\n",
    "different mounts or versions can vary.\n",
    "\n",
    "This cell prints:\n",
    "\n",
    "- a list of expected filenames that are found\n",
    "- a quick top-level directory listing (first ~50 entries)\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "502fde2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T11:53:30.522337Z",
     "start_time": "2026-01-30T11:53:30.468243Z"
    }
   },
   "source": [
    "EXPECTED = [\n",
    "    \"followers.csv.gz\",\n",
    "    \"interactions.csv.gz\",\n",
    "    \"feed_bookmarks.csv\",\n",
    "    \"user_posts.tar.gz\",\n",
    "    \"graphs.tar.gz\",\n",
    "    \"feed_posts.tar.gz\",\n",
    "    \"feed_posts_likes.tar.gz\",\n",
    "]\n",
    "\n",
    "found = {}\n",
    "for name in EXPECTED:\n",
    "    p = DATASET_DIR / name\n",
    "    if p.exists():\n",
    "        found[name] = p\n",
    "\n",
    "print(\"Found expected files:\")\n",
    "for k, v in found.items():\n",
    "    print(f\"  - {k}: {v}\")\n",
    "\n",
    "print(\"\\nTop-level listing (first 50 entries):\")\n",
    "for p in sorted(DATASET_DIR.iterdir())[:50]:\n",
    "    print(\" \", p.name)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found expected files:\n",
      "  - followers.csv.gz: /home/rescic/dezinfo_data/bluesky/followers.csv.gz\n",
      "  - interactions.csv.gz: /home/rescic/dezinfo_data/bluesky/interactions.csv.gz\n",
      "  - feed_bookmarks.csv: /home/rescic/dezinfo_data/bluesky/feed_bookmarks.csv\n",
      "  - user_posts.tar.gz: /home/rescic/dezinfo_data/bluesky/user_posts.tar.gz\n",
      "  - graphs.tar.gz: /home/rescic/dezinfo_data/bluesky/graphs.tar.gz\n",
      "  - feed_posts.tar.gz: /home/rescic/dezinfo_data/bluesky/feed_posts.tar.gz\n",
      "  - feed_posts_likes.tar.gz: /home/rescic/dezinfo_data/bluesky/feed_posts_likes.tar.gz\n",
      "\n",
      "Top-level listing (first 50 entries):\n",
      "  feed_bookmarks.csv\n",
      "  feed_posts.tar.gz\n",
      "  feed_posts_likes.tar.gz\n",
      "  followers.csv.gz\n",
      "  graphs.tar.gz\n",
      "  interactions.csv.gz\n",
      "  scripts\n",
      "  scripts.tar.gz\n",
      "  user_posts.tar.gz\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "6e17d429",
   "metadata": {},
   "source": [
    "## 3) Peek at CSV / CSV.GZ files (schema + a few rows)\n",
    "\n",
    "Large CSV files can be huge, so we only read the first few lines to infer columns and get a feel for the data.\n",
    "\n",
    "Notes:\n",
    "\n",
    "- `pandas.read_csv(..., nrows=...)` is safe for quick peeks\n",
    "- for `.csv.gz`, pandas detects compression automatically from the extension\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "99632e55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T11:53:36.875499Z",
     "start_time": "2026-01-30T11:53:35.576879Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "def peek_csv(path: Path, nrows: int = 5, **kwargs) -> pd.DataFrame:\n",
    "    return pd.read_csv(path, nrows=nrows, **kwargs)\n",
    "\n",
    "# followers.csv.gz is typically a 2-column edge list: (u, v)\n",
    "if \"followers.csv.gz\" in found:\n",
    "    followers_head = peek_csv(found[\"followers.csv.gz\"], nrows=10, header=None, names=[\"u\", \"v\"])\n",
    "    display(followers_head)\n",
    "\n",
    "# interactions.csv.gz is typically 6 integers:\n",
    "# (user_id, replied_author, thread_root_author, reposted_author, quoted_author, date)\n",
    "if \"interactions.csv.gz\" in found:\n",
    "    interactions_head = peek_csv(\n",
    "        found[\"interactions.csv.gz\"],\n",
    "        nrows=10,\n",
    "        header=None,\n",
    "        names=[\"user_id\", \"replied_author\", \"thread_root_author\", \"reposted_author\", \"quoted_author\", \"date\"],\n",
    "    )\n",
    "    display(interactions_head)\n",
    "\n",
    "# feed_bookmarks.csv often has column headers (but we don't assume the exact schema)\n",
    "if \"feed_bookmarks.csv\" in found:\n",
    "    feed_bookmarks_head = peek_csv(found[\"feed_bookmarks.csv\"], nrows=10)\n",
    "    display(feed_bookmarks_head)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   u    v\n",
       "0  0    1\n",
       "1  0   10\n",
       "2  0  100\n",
       "3  0  101\n",
       "4  0  102\n",
       "5  0  103\n",
       "6  0  104\n",
       "7  0  105\n",
       "8  0  106\n",
       "9  0  107"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u</th>\n",
       "      <th>v</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "   user_id  replied_author  thread_root_author  reposted_author  \\\n",
       "0   836672             NaN                 NaN           833271   \n",
       "1   836672             NaN                 NaN            61971   \n",
       "2   836672             NaN                 NaN            47191   \n",
       "3   836672             NaN                 NaN            17234   \n",
       "4   836672             NaN                 NaN            20490   \n",
       "5   836672             NaN                 NaN            61971   \n",
       "6   836672             NaN                 NaN            44299   \n",
       "7   836672             NaN                 NaN            61971   \n",
       "8   836672             NaN                 NaN            20490   \n",
       "9   836672             NaN                 NaN            20490   \n",
       "\n",
       "   quoted_author          date  \n",
       "0            NaN  202309192352  \n",
       "1            NaN  202310021913  \n",
       "2            NaN  202309231547  \n",
       "3            NaN  202309301358  \n",
       "4            NaN  202307261536  \n",
       "5            NaN  202309162126  \n",
       "6            NaN  202309201818  \n",
       "7            NaN  202309252042  \n",
       "8            NaN  202309232023  \n",
       "9            NaN  202308011726  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>replied_author</th>\n",
       "      <th>thread_root_author</th>\n",
       "      <th>reposted_author</th>\n",
       "      <th>quoted_author</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>836672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>833271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202309192352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>836672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202310021913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>836672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47191</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202309231547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>836672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17234</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202309301358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>836672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202307261536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>836672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202309162126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>836672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202309201818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>836672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61971</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202309252042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>836672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202309232023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>836672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>202308011726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "   Science   408833  202309192111\n",
       "0  Science   204992  202307290107\n",
       "1  Science  1798953  202309232103\n",
       "2  Science  1428436  202311051321\n",
       "3  Science   976464  202309131041\n",
       "4  Science   325292  202310130606\n",
       "5  Science   472493  202308100948\n",
       "6  Science  1425781  202307290147\n",
       "7  Science   147657  202306081030\n",
       "8  Science    88914  202311091201\n",
       "9  Science  1667057  202309221235"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Science</th>\n",
       "      <th>408833</th>\n",
       "      <th>202309192111</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Science</td>\n",
       "      <td>204992</td>\n",
       "      <td>202307290107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Science</td>\n",
       "      <td>1798953</td>\n",
       "      <td>202309232103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Science</td>\n",
       "      <td>1428436</td>\n",
       "      <td>202311051321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Science</td>\n",
       "      <td>976464</td>\n",
       "      <td>202309131041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Science</td>\n",
       "      <td>325292</td>\n",
       "      <td>202310130606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Science</td>\n",
       "      <td>472493</td>\n",
       "      <td>202308100948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Science</td>\n",
       "      <td>1425781</td>\n",
       "      <td>202307290147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Science</td>\n",
       "      <td>147657</td>\n",
       "      <td>202306081030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Science</td>\n",
       "      <td>88914</td>\n",
       "      <td>202311091201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Science</td>\n",
       "      <td>1667057</td>\n",
       "      <td>202309221235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "fa8417ee",
   "metadata": {},
   "source": [
    "## 4) Streaming graph stats from `followers.csv.gz`\n",
    "\n",
    "`followers.csv.gz` is a directed follower graph. To avoid loading everything into RAM, we:\n",
    "\n",
    "- stream the file in `chunksize` batches\n",
    "- update `out_degree` and `in_degree` counters incrementally\n",
    "- report:\n",
    "  - number of edges\n",
    "  - number of unique sources/targets seen\n",
    "  - basic distribution summaries\n",
    "\n",
    "If the dataset is extremely large, you can **reduce memory** further by:\n",
    "- computing only summary stats (without storing full counters), or\n",
    "- sampling edges.\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "5c1953e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-30T11:56:00.430450Z",
     "start_time": "2026-01-30T11:53:43.435778Z"
    }
   },
   "source": [
    "from collections import Counter\n",
    "from typing import Tuple\n",
    "import numpy as np\n",
    "\n",
    "def stream_edge_counts_from_csv_gz(path: Path, chunksize: int = 2_000_000) -> Tuple[int, Counter, Counter]:\n",
    "    out_deg = Counter()\n",
    "    in_deg = Counter()\n",
    "    m = 0\n",
    "\n",
    "    for chunk in pd.read_csv(path, header=None, names=[\"u\", \"v\"], chunksize=chunksize):\n",
    "        m += len(chunk)\n",
    "        out_deg.update(chunk[\"u\"].astype(\"int64\").tolist())\n",
    "        in_deg.update(chunk[\"v\"].astype(\"int64\").tolist())\n",
    "\n",
    "    return m, out_deg, in_deg\n",
    "\n",
    "def summarize_counter(counter: Counter, label: str) -> None:\n",
    "    vals = np.fromiter(counter.values(), dtype=np.int64)\n",
    "    if len(vals) == 0:\n",
    "        print(f\"{label}: (empty)\")\n",
    "        return\n",
    "    qs = np.quantile(vals, [0.5, 0.9, 0.99, 0.999])\n",
    "    print(f\"\\n{label} summary\")\n",
    "    print(\"  nodes:\", len(vals))\n",
    "    print(\"  mean:\", float(vals.mean()))\n",
    "    print(\"  median/p90/p99/p99.9:\", qs)\n",
    "\n",
    "if \"followers.csv.gz\" in found:\n",
    "    m_edges, out_deg, in_deg = stream_edge_counts_from_csv_gz(found[\"followers.csv.gz\"], chunksize=1_000_000)\n",
    "    print(\"Followers edges:\", m_edges)\n",
    "    print(\"Unique sources (out-degree):\", len(out_deg))\n",
    "    print(\"Unique targets (in-degree):\", len(in_deg))\n",
    "\n",
    "    summarize_counter(out_deg, \"Out-degree\")\n",
    "    summarize_counter(in_deg, \"In-degree\")\n",
    "else:\n",
    "    print(\"followers.csv.gz not found; skipping follower graph stats.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Followers edges: 144581603\n",
      "Unique sources (out-degree): 3956887\n",
      "Unique targets (in-degree): 3222994\n",
      "\n",
      "Out-degree summary\n",
      "  nodes: 3956887\n",
      "  mean: 36.53922970254142\n",
      "  median/p90/p99/p99.9: [   9.   77.  394. 1362.]\n",
      "\n",
      "In-degree summary\n",
      "  nodes: 3222994\n",
      "  mean: 44.85940805350553\n",
      "  median/p90/p99/p99.9: [   5.      70.     581.    3246.014]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "7cc42bae",
   "metadata": {},
   "source": [
    "## 5) Peek inside `.tar.gz` archives without extracting\n",
    "\n",
    "Some parts of the dataset are shipped as `.tar.gz` archives (e.g., `user_posts.tar.gz`, `graphs.tar.gz`).\n",
    "\n",
    "Extracting can be slow and can duplicate a lot of data on disk — instead we:\n",
    "\n",
    "- list a few member filenames inside the tarball\n",
    "- read the first few lines of a selected member file\n",
    "- if the member appears to be JSONL, parse the first few JSON objects\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "dfd11ca2",
   "metadata": {},
   "source": [
    "import tarfile\n",
    "import io\n",
    "import json\n",
    "\n",
    "def list_tar_members(tar_path: Path, max_members: int = 30) -> list[str]:\n",
    "    with tarfile.open(tar_path, mode=\"r:gz\") as tf:\n",
    "        names = [m.name for m in tf.getmembers() if m.isfile()]\n",
    "    return names[:max_members]\n",
    "\n",
    "def peek_first_text_lines_in_tar(\n",
    "    tar_path: Path,\n",
    "    member_name: str | None = None,\n",
    "    nlines: int = 5,\n",
    "    encoding: str = \"utf-8\",\n",
    ") -> list[str]:\n",
    "    lines: list[str] = []\n",
    "    with tarfile.open(tar_path, mode=\"r:gz\") as tf:\n",
    "        members = [m for m in tf.getmembers() if m.isfile()]\n",
    "        assert members, f\"No file members in {tar_path}\"\n",
    "        target = next((m for m in members if m.name == member_name), members[0])\n",
    "\n",
    "        f = tf.extractfile(target)\n",
    "        assert f is not None, f\"Could not extract member: {target.name}\"\n",
    "        txt = io.TextIOWrapper(f, encoding=encoding, errors=\"replace\")\n",
    "        for _ in range(nlines):\n",
    "            line = txt.readline()\n",
    "            if not line:\n",
    "                break\n",
    "            lines.append(line.rstrip(\"\\n\"))\n",
    "    return lines\n",
    "\n",
    "def peek_first_json_objects_in_tar_jsonl(\n",
    "    tar_path: Path,\n",
    "    member_name: str | None = None,\n",
    "    n: int = 3,\n",
    ") -> list[dict]:\n",
    "    objs: list[dict] = []\n",
    "    with tarfile.open(tar_path, mode=\"r:gz\") as tf:\n",
    "        members = [m for m in tf.getmembers() if m.isfile()]\n",
    "        assert members, f\"No file members in {tar_path}\"\n",
    "        target = next((m for m in members if m.name == member_name), members[0])\n",
    "\n",
    "        f = tf.extractfile(target)\n",
    "        assert f is not None, f\"Could not extract member: {target.name}\"\n",
    "        txt = io.TextIOWrapper(f, encoding=\"utf-8\", errors=\"replace\")\n",
    "        for line in txt:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            try:\n",
    "                objs.append(json.loads(line))\n",
    "            except json.JSONDecodeError:\n",
    "                break\n",
    "            if len(objs) >= n:\n",
    "                break\n",
    "    return objs\n",
    "\n",
    "# user posts archive: often JSONL\n",
    "if \"user_posts.tar.gz\" in found:\n",
    "    tarp = found[\"user_posts.tar.gz\"]\n",
    "    members = list_tar_members(tarp, max_members=20)\n",
    "    print(\"user_posts.tar.gz sample members:\")\n",
    "    for n in members:\n",
    "        print(\" \", n)\n",
    "\n",
    "    objs = peek_first_json_objects_in_tar_jsonl(tarp, member_name=None, n=3)\n",
    "    if objs:\n",
    "        print(\"\\nFirst JSON objects from first member:\")\n",
    "        display(objs)\n",
    "    else:\n",
    "        print(\"\\nCould not parse JSON objects from first member; showing raw lines instead:\")\n",
    "        lines = peek_first_text_lines_in_tar(tarp, member_name=None, nlines=10)\n",
    "        print(\"\\n\".join(lines))\n",
    "\n",
    "# graphs archive: could be edge lists / csv / jsonl depending on release\n",
    "if \"graphs.tar.gz\" in found:\n",
    "    tarp = found[\"graphs.tar.gz\"]\n",
    "    members = list_tar_members(tarp, max_members=20)\n",
    "    print(\"\\ngraphs.tar.gz sample members:\")\n",
    "    for n in members:\n",
    "        print(\" \", n)\n",
    "\n",
    "    lines = peek_first_text_lines_in_tar(tarp, member_name=None, nlines=10)\n",
    "    print(\"\\nFirst 10 lines from first member:\")\n",
    "    print(\"\\n\".join(lines))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1dc940d1d5759792"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
